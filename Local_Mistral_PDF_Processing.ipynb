{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vg-55/btc_dataset/blob/main/Local_Mistral_PDF_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the Katana ML `llm-mistral-invoice-cpu` Project"
      ],
      "metadata": {
        "id": "DnDsmKegTWN2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rHPmILRRmTJ",
        "outputId": "e07612e8-deb6-4e8c-a4b6-9be985ded1ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llm-mistral-invoice-cpu'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 54 (delta 16), reused 47 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (54/54), 54.98 KiB | 1.83 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/katanaml/llm-mistral-invoice-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enter the `llm-mistral-invoice-cpu` folder"
      ],
      "metadata": {
        "id": "NOJM1TuQTraR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd llm-mistral-invoice-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCD0Zh1RSMMq",
        "outputId": "196d486c-c058-46f0-e7d1-271ca85d1f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/llm-mistral-invoice-cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install all the required Python libraries"
      ],
      "metadata": {
        "id": "rXjm_75wTtUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdcvvd29SPFA",
        "outputId": "77ff1c70-0c6a-4b12-df63-57f1564ad901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the quantized LLM from HF Model Hub to run it Locally"
      ],
      "metadata": {
        "id": "3vD0RwdRTwOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm using 2-bit quantized model as Google Colab has just 12 GB RAM. If you have got a better machine, download better model!"
      ],
      "metadata": {
        "id": "ywdXbqb6IBf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q2_K.gguf -P models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqUe96tUSQ94",
        "outputId": "6f50137d-997e-4dec-ac57-a103446ffe6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-18 04:52:15--  https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q2_K.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.4, 18.172.134.24, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/46/12/46124cd8d4788fd8e0879883abfc473f247664b987955cc98a08658f7df6b826/f27558927c82a62367ba29337af784d7502682c0fe01b2ca2a369fdaeaa61ea4?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27mistral-7b-instruct-v0.1.Q2_K.gguf%3B+filename%3D%22mistral-7b-instruct-v0.1.Q2_K.gguf%22%3B&Expires=1697862872&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5Nzg2Mjg3Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy80Ni8xMi80NjEyNGNkOGQ0Nzg4ZmQ4ZTA4Nzk4ODNhYmZjNDczZjI0NzY2NGI5ODc5NTVjYzk4YTA4NjU4ZjdkZjZiODI2L2YyNzU1ODkyN2M4MmE2MjM2N2JhMjkzMzdhZjc4NGQ3NTAyNjgyYzBmZTAxYjJjYTJhMzY5ZmRhZWFhNjFlYTQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=qCgPDf8B1CBImn--6Vmevgdl8IbZAG6JUMAeMWX5wOKqzvFmImaPWgWxMtRHHq6Ck-%7Eo02Ykp9S2rAUlmOKaeO5HMTiie-HOhLrVRUhy-3CyvdzQgX9v%7EI%7EDSHrdhf3lwjrcTz-jMftlthAH6zEVna3CwDD9HqJgDJyWbrCBCimZDDaaeNdMQQw5SmifDe3clzwbIPVNgI2EG8USRwsWFIf0ygAoeKrxMuxfJkyroWf%7E2dmFpDI2vdpmyaH-Rpk1uAK1ASXmdDDfViO7QdiIx9lC3jCvLbs%7E%7EhB4YmSjG8tDA5IC11j1Sk6Trua-rW1MFQZIjjhHMSacMFLf3AjVNQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-10-18 04:52:15--  https://cdn-lfs.huggingface.co/repos/46/12/46124cd8d4788fd8e0879883abfc473f247664b987955cc98a08658f7df6b826/f27558927c82a62367ba29337af784d7502682c0fe01b2ca2a369fdaeaa61ea4?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27mistral-7b-instruct-v0.1.Q2_K.gguf%3B+filename%3D%22mistral-7b-instruct-v0.1.Q2_K.gguf%22%3B&Expires=1697862872&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5Nzg2Mjg3Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy80Ni8xMi80NjEyNGNkOGQ0Nzg4ZmQ4ZTA4Nzk4ODNhYmZjNDczZjI0NzY2NGI5ODc5NTVjYzk4YTA4NjU4ZjdkZjZiODI2L2YyNzU1ODkyN2M4MmE2MjM2N2JhMjkzMzdhZjc4NGQ3NTAyNjgyYzBmZTAxYjJjYTJhMzY5ZmRhZWFhNjFlYTQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=qCgPDf8B1CBImn--6Vmevgdl8IbZAG6JUMAeMWX5wOKqzvFmImaPWgWxMtRHHq6Ck-%7Eo02Ykp9S2rAUlmOKaeO5HMTiie-HOhLrVRUhy-3CyvdzQgX9v%7EI%7EDSHrdhf3lwjrcTz-jMftlthAH6zEVna3CwDD9HqJgDJyWbrCBCimZDDaaeNdMQQw5SmifDe3clzwbIPVNgI2EG8USRwsWFIf0ygAoeKrxMuxfJkyroWf%7E2dmFpDI2vdpmyaH-Rpk1uAK1ASXmdDDfViO7QdiIx9lC3jCvLbs%7E%7EhB4YmSjG8tDA5IC11j1Sk6Trua-rW1MFQZIjjhHMSacMFLf3AjVNQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.27, 18.154.185.94, 18.154.185.26, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3083097760 (2.9G) [binary/octet-stream]\n",
            "Saving to: ‘models/mistral-7b-instruct-v0.1.Q2_K.gguf’\n",
            "\n",
            "mistral-7b-instruct 100%[===================>]   2.87G   194MB/s    in 18s     \n",
            "\n",
            "2023-10-18 04:52:33 (166 MB/s) - ‘models/mistral-7b-instruct-v0.1.Q2_K.gguf’ saved [3083097760/3083097760]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy text PDF files to the data folder"
      ],
      "metadata": {
        "id": "9sx5PSTTT4MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFhXD1S2S1fN",
        "outputId": "7d7a71f5-1e26-4534-bb53-861a3513ab06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "invoice_1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Ingestion"
      ],
      "metadata": {
        "id": "BH7wiDw9T-r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python ingest.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTSbBMYKT6LZ",
        "outputId": "d9229083-88b8-460e-ee52-6746d022e503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rDownloading (…)a8e1d/.gitattributes:   0% 0.00/1.18k [00:00<?, ?B/s]\rDownloading (…)a8e1d/.gitattributes: 100% 1.18k/1.18k [00:00<00:00, 5.77MB/s]\n",
            "\rDownloading (…)_Pooling/config.json:   0% 0.00/190 [00:00<?, ?B/s]\rDownloading (…)_Pooling/config.json: 100% 190/190 [00:00<00:00, 941kB/s]\n",
            "Downloading (…)b20bca8e1d/README.md: 100% 10.6k/10.6k [00:00<00:00, 37.6MB/s]\n",
            "Downloading (…)0bca8e1d/config.json: 100% 571/571 [00:00<00:00, 2.78MB/s]\n",
            "Downloading (…)ce_transformers.json: 100% 116/116 [00:00<00:00, 467kB/s]\n",
            "Downloading (…)e1d/data_config.json: 100% 39.3k/39.3k [00:00<00:00, 4.19MB/s]\n",
            "Downloading pytorch_model.bin: 100% 438M/438M [00:02<00:00, 162MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 318kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 239/239 [00:00<00:00, 929kB/s]\n",
            "Downloading (…)a8e1d/tokenizer.json: 100% 466k/466k [00:00<00:00, 13.1MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 363/363 [00:00<00:00, 1.35MB/s]\n",
            "Downloading (…)8e1d/train_script.py: 100% 13.1k/13.1k [00:00<00:00, 35.3MB/s]\n",
            "Downloading (…)b20bca8e1d/vocab.txt: 100% 232k/232k [00:00<00:00, 4.90MB/s]\n",
            "Downloading (…)bca8e1d/modules.json: 100% 349/349 [00:00<00:00, 1.43MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q&A Time"
      ],
      "metadata": {
        "id": "h3sbMdCgUNlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py \"what is the name of the seller ?\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kOi3zzuT_gW",
        "outputId": "cc1325ac-a984-4d8c-a78b-3489c5054f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer: The name of the seller is Chapman, Kim and Green.\n",
            "==================================================\n",
            "Time to retrieve answer: 383.888912356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "383 / 60"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frju7mEfUSjp",
        "outputId": "b3f0af41-f099-49b8-d006-e549baa322fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.383333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AqAUSr5XQU2d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}